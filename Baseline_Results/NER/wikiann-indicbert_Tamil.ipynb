{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================\n# 1. INSTALL DEPENDENCIES\n# ============================================\n\nprint(\"Installing dependencies...\")\n!pip install -q -U pip\n!pip install -q -U \"transformers>=4.31.0\" \"huggingface_hub>=0.18.0\"\n!pip install -q git+https://github.com/csebuetnlp/normalizer\n!pip install -q evaluate seqeval datasets accelerate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:46:44.246296Z","iopub.execute_input":"2025-10-23T13:46:44.246959Z","iopub.status.idle":"2025-10-23T13:48:47.918646Z","shell.execute_reply.started":"2025-10-23T13:46:44.246932Z","shell.execute_reply":"2025-10-23T13:48:47.917922Z"}},"outputs":[{"name":"stdout","text":"Installing dependencies...\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[33m  DEPRECATION: Building 'normalizer' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'normalizer'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n\u001b[0m  Building wheel for normalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[33m  DEPRECATION: Building 'emoji' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'emoji'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n\u001b[0m  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[33m  DEPRECATION: Building 'ftfy' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'ftfy'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n\u001b[0m  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[33m  DEPRECATION: Building 'seqeval' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'seqeval'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n\u001b[0m  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ============================================\n# 2. IMPORTS\n# ============================================\n\nprint(\"\\nImporting libraries...\")\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForTokenClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForTokenClassification\n)\nimport evaluate\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:48:47.920254Z","iopub.execute_input":"2025-10-23T13:48:47.920964Z","iopub.status.idle":"2025-10-23T13:49:23.267222Z","shell.execute_reply.started":"2025-10-23T13:48:47.920942Z","shell.execute_reply":"2025-10-23T13:49:23.266648Z"}},"outputs":[{"name":"stdout","text":"\nImporting libraries...\n","output_type":"stream"},{"name":"stderr","text":"2025-10-23 13:49:04.299863: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761227344.752730      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761227344.890641      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================\n# 3. GPU CHECK\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"GPU DIAGNOSTIC CHECK\")\nprint(\"=\"*60)\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"CUDA version: {torch.version.cuda if torch.cuda.is_available() else 'N/A'}\")\n\nif torch.cuda.is_available():\n    print(f\"GPU count: {torch.cuda.device_count()}\")\n    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n    device = torch.device(\"cuda\")\n    print(\"‚úì GPU is available and will be used!\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"‚ö†Ô∏è WARNING: No GPU detected! Training will be SLOW on CPU\")\n    print(\"In Colab: Runtime > Change runtime type > Hardware accelerator > GPU\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:49:23.267913Z","iopub.execute_input":"2025-10-23T13:49:23.268451Z","iopub.status.idle":"2025-10-23T13:49:23.274355Z","shell.execute_reply.started":"2025-10-23T13:49:23.268423Z","shell.execute_reply":"2025-10-23T13:49:23.273701Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nGPU DIAGNOSTIC CHECK\n============================================================\nPyTorch version: 2.6.0+cu124\nCUDA available: True\nCUDA version: 12.4\nGPU count: 2\nGPU name: Tesla T4\nGPU memory: 15.83 GB\n‚úì GPU is available and will be used!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ============================================\n# 4. LOAD DATASETS\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"LOADING WIKIANN TAMIL DATASET (Training)\")\nprint(\"=\"*60)\ntrain_dataset = load_dataset(\"wikiann\", \"ta\")\nprint(\"Tamil dataset for training:\")\nprint(train_dataset)\nprint(f\"\\nTrain size: {len(train_dataset['train'])}\")\nprint(f\"Validation size: {len(train_dataset['validation'])}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"LOADING WIKIANN BANGLA DATASET (Testing - Cross-lingual Transfer)\")\nprint(\"=\"*60)\ntest_dataset = load_dataset(\"wikiann\", \"bn\")\nprint(\"Bangla dataset for testing:\")\nprint(test_dataset)\nprint(f\"Test size: {len(test_dataset['test'])}\")\n\n# Use Tamil for training/validation, Bangla for test\ndataset = {\n    \"train\": train_dataset[\"train\"],\n    \"validation\": train_dataset[\"validation\"],\n    \"test\": test_dataset[\"test\"]\n}\n\nprint(\"\\nSample from Tamil training set:\")\nprint(dataset[\"train\"][0])\n\nlabel_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\nprint(f\"\\nNER Labels: {label_list}\")\n\nprint(\"\\n\" + \"-\"*60)\nprint(\"SAMPLE TAMIL SENTENCES WITH TAGS (Training Data)\")\nprint(\"-\"*60)\nfor i in range(3):\n    tokens = dataset[\"train\"][i][\"tokens\"]\n    tags = [label_list[t] for t in dataset[\"train\"][i][\"ner_tags\"]]\n    print(f\"\\nSentence {i+1}:\")\n    print(\"Tokens:\", \" \".join(tokens))\n    print(\"Tags:  \", \" \".join(tags))\n\nprint(\"\\n\" + \"-\"*60)\nprint(\"SAMPLE BANGLA SENTENCES (Test Data - Cross-lingual Evaluation)\")\nprint(\"-\"*60)\nfor i in range(2):\n    tokens = dataset[\"test\"][i][\"tokens\"]\n    tags = [label_list[t] for t in dataset[\"test\"][i][\"ner_tags\"]]\n    print(f\"\\nSentence {i+1}:\")\n    print(\"Tokens:\", \" \".join(tokens))\n    print(\"Tags:  \", \" \".join(tags))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:49:23.276216Z","iopub.execute_input":"2025-10-23T13:49:23.276394Z","iopub.status.idle":"2025-10-23T13:49:32.898844Z","shell.execute_reply.started":"2025-10-23T13:49:23.276380Z","shell.execute_reply":"2025-10-23T13:49:32.898198Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nLOADING WIKIANN TAMIL DATASET (Training)\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e0ecb75f1924383ae8cd5fee22f1ef0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ta/validation-00000-of-00001.parquet:   0%|          | 0.00/92.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccdd31de72564a62980fabf248d141fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ta/test-00000-of-00001.parquet:   0%|          | 0.00/92.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ad7a40d8b784174905a65a59c37526b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ta/train-00000-of-00001.parquet:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d5444d19ec84d7a8fd4564fee86f083"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"918a35b7deb74d5ba0aff2daa23c808e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ac647e78a5941e4ae5db5e12b32d553"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/15000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1199137d372f4fce8780749d25f29fb4"}},"metadata":{}},{"name":"stdout","text":"Tamil dataset for training:\nDatasetDict({\n    validation: Dataset({\n        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n        num_rows: 1000\n    })\n    test: Dataset({\n        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n        num_rows: 1000\n    })\n    train: Dataset({\n        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n        num_rows: 15000\n    })\n})\n\nTrain size: 15000\nValidation size: 1000\n\n============================================================\nLOADING WIKIANN BANGLA DATASET (Testing - Cross-lingual Transfer)\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"bn/validation-00000-of-00001.parquet:   0%|          | 0.00/56.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c377d43375e249b8b49c386470edcb5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bn/test-00000-of-00001.parquet:   0%|          | 0.00/57.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82ad57eddb1742128e304d5e0ca43620"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bn/train-00000-of-00001.parquet:   0%|          | 0.00/554k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d871baeec5343168180486292f5789a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25b468c4537648e59cf255e9497f918c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34cd206a90db43e491bbfbb0b58523fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28edd79266464319887311e64f68dee6"}},"metadata":{}},{"name":"stdout","text":"Bangla dataset for testing:\nDatasetDict({\n    validation: Dataset({\n        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n        num_rows: 1000\n    })\n    test: Dataset({\n        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n        num_rows: 1000\n    })\n    train: Dataset({\n        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n        num_rows: 10000\n    })\n})\nTest size: 1000\n\nSample from Tamil training set:\n{'tokens': ['‡Æá‡Æô‡Øç‡Æï‡Æø‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç', '‡ÆÖ‡Æ∞‡Æö', '‡ÆÆ‡Æ∞‡ÆÆ‡Øç', '‡Æ§‡Øá‡Æµ‡Æ©‡ÆÆ‡Øç‡Æ™‡Æø‡ÆØ‡Æ§‡ØÄ‡Æö', '‡ÆÆ‡Æ©‡Øç‡Æ©‡Æ©‡Øç', '‡Æï‡Ææ‡Æ≤‡Æ§‡Øç‡Æ§‡Æø‡Æ≤‡Øá‡ÆØ‡Øá', '‡ÆÖ‡Æ©‡ØÅ‡Æ∞‡Ææ‡Æ§‡Æ™‡ØÅ‡Æ∞‡Æ§‡Øç‡Æ§‡Æø‡Æ≤‡Æø‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç', '‡Æö‡Æø‡Æ±‡ØÄ', '‡ÆÆ‡Æï‡Ææ‡Æ™‡Øã‡Æ§‡Æø‡ÆØ‡Æø‡Æ≤‡Æø‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡ØÅ', '‡ÆÆ‡ØÅ‡Æ§‡Æ≤‡Ææ‡Æµ‡Æ§‡Ææ‡Æï‡Æ™‡Øç', '‡Æ™‡Æø‡Æ∞‡Æø‡Æ§‡Øç‡Æ§‡ØÜ‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ', '‡Æ®‡Æü‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡Æ§‡Ææ‡Æï‡ØÅ‡ÆÆ‡Øç', '.'], 'ner_tags': [0, 5, 6, 1, 0, 0, 0, 3, 4, 0, 0, 0, 0], 'langs': ['ta', 'ta', 'ta', 'ta', 'ta', 'ta', 'ta', 'ta', 'ta', 'ta', 'ta', 'ta', 'ta'], 'spans': ['LOC: ‡ÆÖ‡Æ∞‡Æö ‡ÆÆ‡Æ∞‡ÆÆ‡Øç', 'PER: ‡Æ§‡Øá‡Æµ‡Æ©‡ÆÆ‡Øç‡Æ™‡Æø‡ÆØ‡Æ§‡ØÄ‡Æö', 'ORG: ‡Æö‡Æø‡Æ±‡ØÄ ‡ÆÆ‡Æï‡Ææ‡Æ™‡Øã‡Æ§‡Æø‡ÆØ‡Æø‡Æ≤‡Æø‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡ØÅ']}\n\nNER Labels: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n\n------------------------------------------------------------\nSAMPLE TAMIL SENTENCES WITH TAGS (Training Data)\n------------------------------------------------------------\n\nSentence 1:\nTokens: ‡Æá‡Æô‡Øç‡Æï‡Æø‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç ‡ÆÖ‡Æ∞‡Æö ‡ÆÆ‡Æ∞‡ÆÆ‡Øç ‡Æ§‡Øá‡Æµ‡Æ©‡ÆÆ‡Øç‡Æ™‡Æø‡ÆØ‡Æ§‡ØÄ‡Æö ‡ÆÆ‡Æ©‡Øç‡Æ©‡Æ©‡Øç ‡Æï‡Ææ‡Æ≤‡Æ§‡Øç‡Æ§‡Æø‡Æ≤‡Øá‡ÆØ‡Øá ‡ÆÖ‡Æ©‡ØÅ‡Æ∞‡Ææ‡Æ§‡Æ™‡ØÅ‡Æ∞‡Æ§‡Øç‡Æ§‡Æø‡Æ≤‡Æø‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç ‡Æö‡Æø‡Æ±‡ØÄ ‡ÆÆ‡Æï‡Ææ‡Æ™‡Øã‡Æ§‡Æø‡ÆØ‡Æø‡Æ≤‡Æø‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡ØÅ ‡ÆÆ‡ØÅ‡Æ§‡Æ≤‡Ææ‡Æµ‡Æ§‡Ææ‡Æï‡Æ™‡Øç ‡Æ™‡Æø‡Æ∞‡Æø‡Æ§‡Øç‡Æ§‡ØÜ‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ ‡Æ®‡Æü‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡Æ§‡Ææ‡Æï‡ØÅ‡ÆÆ‡Øç .\nTags:   O B-LOC I-LOC B-PER O O O B-ORG I-ORG O O O O\n\nSentence 2:\nTokens: ' '' ‡ÆÖ‡Æ®‡Øç‡Æ§‡ÆÆ‡Ææ‡Æ©‡Øç ‡Æ®‡Æø‡Æï‡Øç‡Æï‡Øã‡Æ™‡Ææ‡Æ∞‡Øç ‡Æ§‡ØÄ‡Æµ‡ØÅ‡Æï‡Æ≥‡Øç '' '\nTags:   O O B-LOC I-LOC I-LOC O O\n\nSentence 3:\nTokens: ‡Æµ‡Æø‡Æ©‡Øç‡Æ∏‡Øç‡Æü‡Æ©‡Øç ‡Æö‡Æ∞‡Øç‡Æö‡Øç‡Æö‡Æø‡Æ≤‡Øç ‡Æ™‡Æ§‡Æµ‡Æø ‡Æá‡Æ¥‡Æ®‡Øç‡Æ§‡Ææ‡Æ∞‡Øç .\nTags:   B-PER I-PER O O O\n\n------------------------------------------------------------\nSAMPLE BANGLA SENTENCES (Test Data - Cross-lingual Evaluation)\n------------------------------------------------------------\n\nSentence 1:\nTokens: ‡¶â‡¶∞‡ßÅ‡¶ó‡ßÅ‡¶Ø‡¶º‡ßá ‡¶ú‡¶æ‡¶§‡ßÄ‡¶Ø‡¶º ‡¶´‡ßÅ‡¶ü‡¶¨‡¶≤ ‡¶¶‡¶≤\nTags:   B-ORG I-ORG I-ORG I-ORG\n\nSentence 2:\nTokens: ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶°‡ßç‡¶∞‡ßÅ ‡¶ú‡ßá‡¶° ‡¶´‡¶æ‡¶Ø‡¶º‡¶æ‡¶∞\nTags:   B-PER I-PER I-PER\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ============================================\n# 5. LOAD TOKENIZER ‚Äî INDICBERT\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"LOADING TOKENIZER (INDICBERT)\")\nprint(\"=\"*60)\nMODEL_NAME = \"ai4bharat/IndicBERTv2-MLM-only\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nprint(f\"Tokenizer loaded: {MODEL_NAME}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:49:32.899495Z","iopub.execute_input":"2025-10-23T13:49:32.899680Z","iopub.status.idle":"2025-10-23T13:49:34.540726Z","shell.execute_reply.started":"2025-10-23T13:49:32.899665Z","shell.execute_reply":"2025-10-23T13:49:34.539919Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nLOADING TOKENIZER (INDICBERT)\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a912e573b1934bdd93380be30c98b7ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.75M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1953f054bab4ccfaa0e08cc0cfd5ee2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5f183b3d43043b389cbdb326924fb4d"}},"metadata":{}},{"name":"stdout","text":"Tokenizer loaded: ai4bharat/IndicBERTv2-MLM-only\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============================================\n# 6. TOKENIZATION FUNCTION\n# ============================================\n\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"],\n        truncation=True,\n        is_split_into_words=True,\n        padding=False,\n        max_length=128\n    )\n\n    all_labels = []\n    for i, labels in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        label_ids = []\n        previous_word_idx = None\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(labels[word_idx])\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n        all_labels.append(label_ids)\n\n    tokenized_inputs[\"labels\"] = all_labels\n    return tokenized_inputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:49:34.541629Z","iopub.execute_input":"2025-10-23T13:49:34.541882Z","iopub.status.idle":"2025-10-23T13:49:34.547206Z","shell.execute_reply.started":"2025-10-23T13:49:34.541865Z","shell.execute_reply":"2025-10-23T13:49:34.546508Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ============================================\n# 7. TOKENIZE DATASET\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TOKENIZING DATASETS\")\nprint(\"=\"*60)\n\n# Tokenize each split separately\ntokenized_train = dataset[\"train\"].map(\n    tokenize_and_align_labels,\n    batched=True,\n    desc=\"Tokenizing Tamil train\"\n)\ntokenized_val = dataset[\"validation\"].map(\n    tokenize_and_align_labels,\n    batched=True,\n    desc=\"Tokenizing Tamil validation\"\n)\ntokenized_test = dataset[\"test\"].map(\n    tokenize_and_align_labels,\n    batched=True,\n    desc=\"Tokenizing Bangla test\"\n)\n\n# Remove unnecessary columns\ntokenized_train = tokenized_train.remove_columns([\"tokens\", \"ner_tags\", \"langs\"])\ntokenized_val = tokenized_val.remove_columns([\"tokens\", \"ner_tags\", \"langs\"])\ntokenized_test = tokenized_test.remove_columns([\"tokens\", \"ner_tags\", \"langs\"])\n\n# Create the tokenized_datasets dictionary\ntokenized_datasets = {\n    \"train\": tokenized_train,\n    \"validation\": tokenized_val,\n    \"test\": tokenized_test\n}\n\nprint(\"Tokenized datasets:\")\nprint(f\"  Train: {len(tokenized_datasets['train'])} samples\")\nprint(f\"  Validation: {len(tokenized_datasets['validation'])} samples\")\nprint(f\"  Test (Bangla): {len(tokenized_datasets['test'])} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:49:34.548056Z","iopub.execute_input":"2025-10-23T13:49:34.548277Z","iopub.status.idle":"2025-10-23T13:49:35.690391Z","shell.execute_reply.started":"2025-10-23T13:49:34.548262Z","shell.execute_reply":"2025-10-23T13:49:35.689682Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTOKENIZING DATASETS\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tokenizing Tamil train:   0%|          | 0/15000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2214dcdfece4f2ab0a15651208a4315"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing Tamil validation:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af930881478045b09b3daa9d2463c725"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing Bangla test:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be5efaf74a3d4dcd9b9a9de11e96bd15"}},"metadata":{}},{"name":"stdout","text":"Tokenized datasets:\n  Train: 15000 samples\n  Validation: 1000 samples\n  Test (Bangla): 1000 samples\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ============================================\n# 8. LOAD MODEL ‚Äî INDICBERT\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"LOADING MODEL (INDICBERT)\")\nprint(\"=\"*60)\nmodel = AutoModelForTokenClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=len(label_list),\n    id2label={i: label for i, label in enumerate(label_list)},\n    label2id={label: i for i, label in enumerate(label_list)}\n)\nmodel = model.to(device)\nprint(f\"Model loaded: {MODEL_NAME}\")\nprint(f\"Model device: {next(model.parameters()).device}\")\nprint(f\"Number of parameters: {model.num_parameters():,}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:49:35.691206Z","iopub.execute_input":"2025-10-23T13:49:35.691405Z","iopub.status.idle":"2025-10-23T13:49:43.051519Z","shell.execute_reply.started":"2025-10-23T13:49:35.691380Z","shell.execute_reply":"2025-10-23T13:49:43.050670Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nLOADING MODEL (INDICBERT)\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/639 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c89f0b3438684d95b6f7a51879ac2b5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea6cef510cb14ad4b0ba21c698154cf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ebe17451224431c9a884041342fca22"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at ai4bharat/IndicBERTv2-MLM-only and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model loaded: ai4bharat/IndicBERTv2-MLM-only\nModel device: cuda:0\nNumber of parameters: 277,456,135\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ============================================\n# 9. SETUP METRICS\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"LOADING METRICS\")\nprint(\"=\"*60)\nmetric = evaluate.load(\"seqeval\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=2)\n\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:49:43.052403Z","iopub.execute_input":"2025-10-23T13:49:43.052767Z","iopub.status.idle":"2025-10-23T13:49:44.617855Z","shell.execute_reply.started":"2025-10-23T13:49:43.052739Z","shell.execute_reply":"2025-10-23T13:49:44.615335Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nLOADING METRICS\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"353442ad6871462390c38ba81fbbfa67"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# ============================================\n# 10. DATA COLLATOR\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SETTING UP DATA COLLATOR\")\nprint(\"=\"*60)\ndata_collator = DataCollatorForTokenClassification(\n    tokenizer=tokenizer,\n    padding=True,\n    label_pad_token_id=-100\n)\nprint(\"Data collator created successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:49:44.626328Z","iopub.execute_input":"2025-10-23T13:49:44.626713Z","iopub.status.idle":"2025-10-23T13:49:44.648329Z","shell.execute_reply.started":"2025-10-23T13:49:44.626681Z","shell.execute_reply":"2025-10-23T13:49:44.647315Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSETTING UP DATA COLLATOR\n============================================================\nData collator created successfully!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ============================================\n# 11. TRAINING ARGUMENTS\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SETTING UP TRAINING ARGUMENTS\")\nprint(\"=\"*60)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results-indicbert-tamil-ner\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=50,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    fp16=torch.cuda.is_available(),\n    push_to_hub=False,\n    save_total_limit=2,\n    report_to=\"none\",\n)\n\nprint(f\"Training device: {training_args.device}\")\nprint(f\"FP16 training: {training_args.fp16}\")\nprint(f\"Batch size: {training_args.per_device_train_batch_size}\")\nprint(f\"Number of epochs: {training_args.num_train_epochs}\")\nprint(\"\\n‚ö†Ô∏è NOTE: Training on TAMIL data, Testing on BANGLA data (Cross-lingual Transfer)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:49:44.649425Z","iopub.execute_input":"2025-10-23T13:49:44.656129Z","iopub.status.idle":"2025-10-23T13:49:47.659140Z","shell.execute_reply.started":"2025-10-23T13:49:44.656097Z","shell.execute_reply":"2025-10-23T13:49:47.658275Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSETTING UP TRAINING ARGUMENTS\n============================================================\nTraining device: cuda:0\nFP16 training: True\nBatch size: 16\nNumber of epochs: 5\n\n‚ö†Ô∏è NOTE: Training on TAMIL data, Testing on BANGLA data (Cross-lingual Transfer)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ============================================\n# 12. CREATE TRAINER\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"CREATING TRAINER\")\nprint(\"=\"*60)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    processing_class=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\nprint(\"Trainer created successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:49:47.660210Z","iopub.execute_input":"2025-10-23T13:49:47.660507Z","iopub.status.idle":"2025-10-23T13:49:48.924933Z","shell.execute_reply.started":"2025-10-23T13:49:47.660479Z","shell.execute_reply":"2025-10-23T13:49:48.924138Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nCREATING TRAINER\n============================================================\nTrainer created successfully!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ============================================\n# 13. START TRAINING\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"STARTING TRAINING\")\nprint(\"=\"*60)\nprint(f\"This will take approximately 15‚Äì25 minutes on a T4 GPU\")\nprint(\"=\"*60 + \"\\n\")\n\ntrainer.train()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING COMPLETED!\")\nprint(\"=\"*60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:49:48.925753Z","iopub.execute_input":"2025-10-23T13:49:48.926162Z","iopub.status.idle":"2025-10-23T14:06:07.613654Z","shell.execute_reply.started":"2025-10-23T13:49:48.926138Z","shell.execute_reply":"2025-10-23T14:06:07.612822Z"}},"outputs":[{"name":"stderr","text":"The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 3}.\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nSTARTING TRAINING\n============================================================\nThis will take approximately 15‚Äì25 minutes on a T4 GPU\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2345/2345 16:14, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.188700</td>\n      <td>0.181388</td>\n      <td>0.801581</td>\n      <td>0.831148</td>\n      <td>0.816097</td>\n      <td>0.941725</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.137000</td>\n      <td>0.149490</td>\n      <td>0.855519</td>\n      <td>0.863934</td>\n      <td>0.859706</td>\n      <td>0.954751</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.099200</td>\n      <td>0.141660</td>\n      <td>0.839314</td>\n      <td>0.881967</td>\n      <td>0.860112</td>\n      <td>0.955985</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.069500</td>\n      <td>0.148929</td>\n      <td>0.860539</td>\n      <td>0.890164</td>\n      <td>0.875101</td>\n      <td>0.958865</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.061600</td>\n      <td>0.153928</td>\n      <td>0.861905</td>\n      <td>0.890164</td>\n      <td>0.875806</td>\n      <td>0.959550</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nTRAINING COMPLETED!\n============================================================\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ============================================\n# 14. FINAL EVALUATION\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"FINAL EVALUATION ON TAMIL VALIDATION SET\")\nprint(\"=\"*60)\neval_results = trainer.evaluate()\nprint(\"\\nTamil Validation Results:\")\nfor key, value in eval_results.items():\n    print(f\"  {key}: {value:.4f}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"CROSS-LINGUAL EVALUATION ON BANGLA TEST SET\")\nprint(\"=\"*60)\nprint(\"‚ö†Ô∏è Testing cross-lingual transfer: Tamil-trained model on Bangla data\")\ntest_results = trainer.evaluate(tokenized_datasets[\"test\"])\nprint(\"\\nBangla Test Results (Cross-lingual Transfer):\")\nfor key, value in test_results.items():\n    print(f\"  {key}: {value:.4f}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRANSFER LEARNING ANALYSIS\")\nprint(\"=\"*60)\nprint(f\"Tamil ‚Üí Tamil F1: {eval_results['eval_f1']:.4f}\")\nprint(f\"Tamil ‚Üí Bangla F1: {test_results['eval_f1']:.4f}\")\ntransfer_gap = eval_results['eval_f1'] - test_results['eval_f1']\nprint(f\"Transfer Gap: {transfer_gap:.4f}\")\nif transfer_gap > 0:\n    print(\"‚úì Model performs better on source language (expected)\")\nelse:\n    print(\"‚ö†Ô∏è Model performs better on target language (unexpected)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T14:06:07.614548Z","iopub.execute_input":"2025-10-23T14:06:07.614839Z","iopub.status.idle":"2025-10-23T14:06:15.507592Z","shell.execute_reply.started":"2025-10-23T14:06:07.614814Z","shell.execute_reply":"2025-10-23T14:06:15.506974Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nFINAL EVALUATION ON TAMIL VALIDATION SET\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='64' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nTamil Validation Results:\n  eval_loss: 0.1539\n  eval_precision: 0.8619\n  eval_recall: 0.8902\n  eval_f1: 0.8758\n  eval_accuracy: 0.9596\n  eval_runtime: 4.0541\n  eval_samples_per_second: 246.6660\n  eval_steps_per_second: 7.8930\n  epoch: 5.0000\n\n============================================================\nCROSS-LINGUAL EVALUATION ON BANGLA TEST SET\n============================================================\n‚ö†Ô∏è Testing cross-lingual transfer: Tamil-trained model on Bangla data\n\nBangla Test Results (Cross-lingual Transfer):\n  eval_loss: 0.5748\n  eval_precision: 0.7756\n  eval_recall: 0.8127\n  eval_f1: 0.7937\n  eval_accuracy: 0.8668\n  eval_runtime: 3.8238\n  eval_samples_per_second: 261.5220\n  eval_steps_per_second: 8.3690\n  epoch: 5.0000\n\n============================================================\nTRANSFER LEARNING ANALYSIS\n============================================================\nTamil ‚Üí Tamil F1: 0.8758\nTamil ‚Üí Bangla F1: 0.7937\nTransfer Gap: 0.0821\n‚úì Model performs better on source language (expected)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ============================================\n# 15. SAVE MODEL\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SAVING FINAL MODEL\")\nprint(\"=\"*60)\ntrainer.save_model(\"./indicbert-tamil-ner-final\")\ntokenizer.save_pretrained(\"./indicbert-tamil-ner-final\")\nprint(\"Model saved to: ./indicbert-tamil-ner-final\")\nprint(\"This model was trained on Tamil and can be used for cross-lingual transfer to Bangla\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T14:06:15.508275Z","iopub.execute_input":"2025-10-23T14:06:15.508594Z","iopub.status.idle":"2025-10-23T14:06:18.288339Z","shell.execute_reply.started":"2025-10-23T14:06:15.508576Z","shell.execute_reply":"2025-10-23T14:06:18.287515Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSAVING FINAL MODEL\n============================================================\nModel saved to: ./indicbert-tamil-ner-final\nThis model was trained on Tamil and can be used for cross-lingual transfer to Bangla\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import shutil\nimport os\n\n# Define the output zip file\noutput_filename = \"kaggle_working_dir.zip\"\n\n# Current working directory\ncurrent_dir = os.getcwd()\n\n# Create a zip of the current directory\nshutil.make_archive(\"kaggle_working_dir\", 'zip', current_dir)\n\nprint(f\"‚úÖ ZIP file created: {output_filename}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T14:06:18.289160Z","iopub.execute_input":"2025-10-23T14:06:18.289419Z","iopub.status.idle":"2025-10-23T14:10:33.501350Z","shell.execute_reply.started":"2025-10-23T14:06:18.289401Z","shell.execute_reply":"2025-10-23T14:10:33.500712Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ZIP file created: kaggle_working_dir.zip\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# ============================================\n# 16. TEST INFERENCE\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TESTING INFERENCE\")\nprint(\"=\"*60)\n\ntest_sentence = dataset[\"test\"][0]\ntest_tokens = test_sentence[\"tokens\"]\nprint(f\"\\nTest sentence: {' '.join(test_tokens)}\")\n\ninputs = tokenizer(\n    test_tokens,\n    is_split_into_words=True,\n    return_tensors=\"pt\",\n    truncation=True,\n    padding=True\n).to(device)\n\nwith torch.no_grad():\n    outputs = model(**inputs)\n    predictions = torch.argmax(outputs.logits, dim=2)\n\npredicted_labels = [label_list[p.item()] for p in predictions[0]]\nword_ids = inputs.word_ids()\n\nfinal_predictions = []\nprevious_word_idx = None\nfor word_idx, pred_label in zip(word_ids, predicted_labels):\n    if word_idx is not None and word_idx != previous_word_idx:\n        final_predictions.append(pred_label)\n        previous_word_idx = word_idx\n\nprint(\"\\nPredicted NER tags:\")\nfor token, pred_tag in zip(test_tokens, final_predictions):\n    print(f\"  {token:20s} -> {pred_tag}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ALL DONE! üéâ\")\nprint(\"=\"*60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T14:10:33.502104Z","iopub.execute_input":"2025-10-23T14:10:33.502287Z","iopub.status.idle":"2025-10-23T14:10:33.675501Z","shell.execute_reply.started":"2025-10-23T14:10:33.502273Z","shell.execute_reply":"2025-10-23T14:10:33.674720Z"}},"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nTESTING INFERENCE\n============================================================\n\nTest sentence: ‡¶â‡¶∞‡ßÅ‡¶ó‡ßÅ‡¶Ø‡¶º‡ßá ‡¶ú‡¶æ‡¶§‡ßÄ‡¶Ø‡¶º ‡¶´‡ßÅ‡¶ü‡¶¨‡¶≤ ‡¶¶‡¶≤\n\nPredicted NER tags:\n  ‡¶â‡¶∞‡ßÅ‡¶ó‡ßÅ‡¶Ø‡¶º‡ßá             -> B-ORG\n  ‡¶ú‡¶æ‡¶§‡ßÄ‡¶Ø‡¶º               -> I-ORG\n  ‡¶´‡ßÅ‡¶ü‡¶¨‡¶≤                -> I-ORG\n  ‡¶¶‡¶≤                   -> I-ORG\n\n============================================================\nALL DONE! üéâ\n============================================================\n","output_type":"stream"}],"execution_count":17}]}