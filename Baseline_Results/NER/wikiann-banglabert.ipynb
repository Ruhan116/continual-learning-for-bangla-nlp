{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================\n# 1. INSTALL DEPENDENCIES\n# ============================================\n\nprint(\"Installing dependencies...\")\n!pip install -q -U pip\n!pip install -q -U \"transformers>=4.31.0\" \"huggingface_hub>=0.18.0\"\n!pip install -q git+https://github.com/csebuetnlp/normalizer\n!pip install -q evaluate seqeval datasets accelerate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:24:12.310955Z","iopub.execute_input":"2025-10-23T09:24:12.311209Z","iopub.status.idle":"2025-10-23T09:24:22.828420Z","shell.execute_reply.started":"2025-10-23T09:24:12.311168Z","shell.execute_reply":"2025-10-23T09:24:22.827511Z"}},"outputs":[{"name":"stdout","text":"Installing dependencies...\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# ============================================\n# 2. IMPORTS\n# ============================================\n\nprint(\"\\nImporting libraries...\")\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForTokenClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForTokenClassification\n)\nimport evaluate\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:24:22.829551Z","iopub.execute_input":"2025-10-23T09:24:22.829831Z","iopub.status.idle":"2025-10-23T09:24:22.835317Z","shell.execute_reply.started":"2025-10-23T09:24:22.829807Z","shell.execute_reply":"2025-10-23T09:24:22.834681Z"}},"outputs":[{"name":"stdout","text":"\nImporting libraries...\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# ============================================\n# 3. GPU CHECK\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"GPU DIAGNOSTIC CHECK\")\nprint(\"=\"*60)\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"CUDA version: {torch.version.cuda if torch.cuda.is_available() else 'N/A'}\")\n\nif torch.cuda.is_available():\n    print(f\"GPU count: {torch.cuda.device_count()}\")\n    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n    device = torch.device(\"cuda\")\n    print(\"‚úì GPU is available and will be used!\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"‚ö†Ô∏è WARNING: No GPU detected! Training will be SLOW on CPU\")\n    print(\"In Colab: Runtime > Change runtime type > Hardware accelerator > GPU\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:24:22.836060Z","iopub.execute_input":"2025-10-23T09:24:22.836350Z","iopub.status.idle":"2025-10-23T09:24:24.001990Z","shell.execute_reply.started":"2025-10-23T09:24:22.836325Z","shell.execute_reply":"2025-10-23T09:24:24.001235Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nGPU DIAGNOSTIC CHECK\n============================================================\nPyTorch version: 2.6.0+cu124\nCUDA available: True\nCUDA version: 12.4\nGPU count: 2\nGPU name: Tesla T4\nGPU memory: 15.83 GB\n‚úì GPU is available and will be used!\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# ============================================\n# 4. LOAD DATASET\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"LOADING WIKIANN BANGLA DATASET\")\nprint(\"=\"*60)\ndataset = load_dataset(\"wikiann\", \"bn\")\nprint(dataset)\nprint(f\"\\nTrain size: {len(dataset['train'])}\")\nprint(f\"Validation size: {len(dataset['validation'])}\")\nprint(f\"Test size: {len(dataset['test'])}\")\n\nprint(\"\\nSample from training set:\")\nprint(dataset[\"train\"][0])\n\nlabel_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\nprint(f\"\\nNER Labels: {label_list}\")\n\nprint(\"\\n\" + \"-\"*60)\nprint(\"SAMPLE SENTENCES WITH TAGS\")\nprint(\"-\"*60)\nfor i in range(3):\n    tokens = dataset[\"train\"][i][\"tokens\"]\n    tags = [label_list[t] for t in dataset[\"train\"][i][\"ner_tags\"]]\n    print(f\"\\nSentence {i+1}:\")\n    print(\"Tokens:\", \" \".join(tokens))\n    print(\"Tags:  \", \" \".join(tags))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:24:24.002850Z","iopub.execute_input":"2025-10-23T09:24:24.003104Z","iopub.status.idle":"2025-10-23T09:24:25.830026Z","shell.execute_reply.started":"2025-10-23T09:24:24.003080Z","shell.execute_reply":"2025-10-23T09:24:25.829370Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nLOADING WIKIANN BANGLA DATASET\n============================================================\nDatasetDict({\n    validation: Dataset({\n        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n        num_rows: 1000\n    })\n    test: Dataset({\n        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n        num_rows: 1000\n    })\n    train: Dataset({\n        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n        num_rows: 10000\n    })\n})\n\nTrain size: 10000\nValidation size: 1000\nTest size: 1000\n\nSample from training set:\n{'tokens': ['‡¶°‡ßç‡¶Ø‡¶æ‡¶®‡¶≠‡¶ø‡¶≤', ',', '‡¶á‡¶≤‡¶ø‡¶®‡¶Ø‡¶º'], 'ner_tags': [5, 6, 6], 'langs': ['bn', 'bn', 'bn'], 'spans': ['LOC: ‡¶°‡ßç‡¶Ø‡¶æ‡¶®‡¶≠‡¶ø‡¶≤ , ‡¶á‡¶≤‡¶ø‡¶®‡¶Ø‡¶º']}\n\nNER Labels: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n\n------------------------------------------------------------\nSAMPLE SENTENCES WITH TAGS\n------------------------------------------------------------\n\nSentence 1:\nTokens: ‡¶°‡ßç‡¶Ø‡¶æ‡¶®‡¶≠‡¶ø‡¶≤ , ‡¶á‡¶≤‡¶ø‡¶®‡¶Ø‡¶º\nTags:   B-LOC I-LOC I-LOC\n\nSentence 2:\nTokens: ‡¶∂‡¶ø‡¶∞‡ßã‡¶®‡¶æ‡¶Æ‡¶π‡ßÄ‡¶® ‡¶∂‡¶ø‡¶∞‡ßã‡¶®‡¶æ‡¶Æ‡¶π‡ßÄ‡¶® '' ( ‡ß®‡ß¶‡ßß‡ß© )\nTags:   B-ORG B-ORG O O O O\n\nSentence 3:\nTokens: ‡¶è‡¶á ‡¶á‡¶â‡¶®‡¶ø‡¶Ø‡¶º‡¶®‡ßá ‡ß© ‡¶ü‡¶ø ‡¶Æ‡ßå‡¶ú‡¶æ ‡¶ì ‡ßß‡ß¶ ‡¶ü‡¶ø ‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ ‡¶Ü‡¶õ‡ßá ‡•§\nTags:   O O O O B-LOC O O O O O O\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# ============================================\n# 5. LOAD TOKENIZER\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"LOADING TOKENIZER\")\nprint(\"=\"*60)\nMODEL_NAME = \"csebuetnlp/banglabert\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nprint(f\"Tokenizer loaded: {MODEL_NAME}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:24:25.830713Z","iopub.execute_input":"2025-10-23T09:24:25.830898Z","iopub.status.idle":"2025-10-23T09:24:26.046433Z","shell.execute_reply.started":"2025-10-23T09:24:25.830880Z","shell.execute_reply":"2025-10-23T09:24:26.045798Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nLOADING TOKENIZER\n============================================================\nTokenizer loaded: csebuetnlp/banglabert\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# ============================================\n# 6. TOKENIZATION FUNCTION\n# ============================================\n\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"],\n        truncation=True,\n        is_split_into_words=True,\n        padding=False,\n        max_length=128\n    )\n\n    all_labels = []\n    for i, labels in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        label_ids = []\n        previous_word_idx = None\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(labels[word_idx])\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n        all_labels.append(label_ids)\n\n    tokenized_inputs[\"labels\"] = all_labels\n    return tokenized_inputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:24:26.047063Z","iopub.execute_input":"2025-10-23T09:24:26.047293Z","iopub.status.idle":"2025-10-23T09:24:26.052551Z","shell.execute_reply.started":"2025-10-23T09:24:26.047266Z","shell.execute_reply":"2025-10-23T09:24:26.051957Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# ============================================\n# 7. TOKENIZE DATASET\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TOKENIZING DATASET\")\nprint(\"=\"*60)\ntokenized_datasets = dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n    desc=\"Tokenizing\"\n)\ntokenized_datasets = tokenized_datasets.remove_columns([\"tokens\", \"ner_tags\", \"langs\"])\nprint(\"Tokenized dataset:\")\nprint(tokenized_datasets)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:24:26.053213Z","iopub.execute_input":"2025-10-23T09:24:26.053464Z","iopub.status.idle":"2025-10-23T09:24:26.167551Z","shell.execute_reply.started":"2025-10-23T09:24:26.053447Z","shell.execute_reply":"2025-10-23T09:24:26.166748Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTOKENIZING DATASET\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1bd94a4abf4485fbb9c3718fe4c8d81"}},"metadata":{}},{"name":"stdout","text":"Tokenized dataset:\nDatasetDict({\n    validation: Dataset({\n        features: ['spans', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 1000\n    })\n    test: Dataset({\n        features: ['spans', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 1000\n    })\n    train: Dataset({\n        features: ['spans', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 10000\n    })\n})\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# ============================================\n# 8. LOAD MODEL\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"LOADING MODEL\")\nprint(\"=\"*60)\nmodel = AutoModelForTokenClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=len(label_list),\n    id2label={i: label for i, label in enumerate(label_list)},\n    label2id={label: i for i, label in enumerate(label_list)}\n)\nmodel = model.to(device)\nprint(f\"Model loaded: {MODEL_NAME}\")\nprint(f\"Model device: {next(model.parameters()).device}\")\nprint(f\"Number of parameters: {model.num_parameters():,}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:24:26.168389Z","iopub.execute_input":"2025-10-23T09:24:26.168677Z","iopub.status.idle":"2025-10-23T09:24:27.271021Z","shell.execute_reply.started":"2025-10-23T09:24:26.168660Z","shell.execute_reply":"2025-10-23T09:24:27.270364Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nLOADING MODEL\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at csebuetnlp/banglabert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model loaded: csebuetnlp/banglabert\nModel device: cuda:0\nNumber of parameters: 110,032,135\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# ============================================\n# 9. SETUP METRICS\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"LOADING METRICS\")\nprint(\"=\"*60)\nmetric = evaluate.load(\"seqeval\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=2)\n\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:24:27.271725Z","iopub.execute_input":"2025-10-23T09:24:27.271906Z","iopub.status.idle":"2025-10-23T09:24:27.794980Z","shell.execute_reply.started":"2025-10-23T09:24:27.271892Z","shell.execute_reply":"2025-10-23T09:24:27.794403Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nLOADING METRICS\n============================================================\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# ============================================\n# 10. DATA COLLATOR\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SETTING UP DATA COLLATOR\")\nprint(\"=\"*60)\ndata_collator = DataCollatorForTokenClassification(\n    tokenizer=tokenizer,\n    padding=True,\n    label_pad_token_id=-100\n)\nprint(\"Data collator created successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:24:27.795742Z","iopub.execute_input":"2025-10-23T09:24:27.796000Z","iopub.status.idle":"2025-10-23T09:24:27.800666Z","shell.execute_reply.started":"2025-10-23T09:24:27.795981Z","shell.execute_reply":"2025-10-23T09:24:27.799856Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSETTING UP DATA COLLATOR\n============================================================\nData collator created successfully!\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# ============================================\n# 11. TRAINING ARGUMENTS\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SETTING UP TRAINING ARGUMENTS\")\nprint(\"=\"*60)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results-banglabert-ner\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=50,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    fp16=torch.cuda.is_available(),\n    push_to_hub=False,\n    save_total_limit=2,\n    report_to=\"none\",\n)\n\nprint(f\"Training device: {training_args.device}\")\nprint(f\"FP16 training: {training_args.fp16}\")\nprint(f\"Batch size: {training_args.per_device_train_batch_size}\")\nprint(f\"Number of epochs: {training_args.num_train_epochs}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:24:27.801400Z","iopub.execute_input":"2025-10-23T09:24:27.801957Z","iopub.status.idle":"2025-10-23T09:24:27.850625Z","shell.execute_reply.started":"2025-10-23T09:24:27.801929Z","shell.execute_reply":"2025-10-23T09:24:27.849978Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSETTING UP TRAINING ARGUMENTS\n============================================================\nTraining device: cuda:0\nFP16 training: True\nBatch size: 16\nNumber of epochs: 5\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# ============================================\n# 12. CREATE TRAINER\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"CREATING TRAINER\")\nprint(\"=\"*60)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    processing_class=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\nprint(\"Trainer created successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:24:27.851346Z","iopub.execute_input":"2025-10-23T09:24:27.851588Z","iopub.status.idle":"2025-10-23T09:24:27.888251Z","shell.execute_reply.started":"2025-10-23T09:24:27.851572Z","shell.execute_reply":"2025-10-23T09:24:27.887483Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nCREATING TRAINER\n============================================================\nTrainer created successfully!\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# ============================================\n# 13. START TRAINING\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"STARTING TRAINING\")\nprint(\"=\"*60)\nprint(f\"This will take approximately 15‚Äì25 minutes on a T4 GPU\")\nprint(\"=\"*60 + \"\\n\")\n\ntrainer.train()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING COMPLETED!\")\nprint(\"=\"*60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:24:27.888991Z","iopub.execute_input":"2025-10-23T09:24:27.889250Z","iopub.status.idle":"2025-10-23T09:29:42.723412Z","shell.execute_reply.started":"2025-10-23T09:24:27.889224Z","shell.execute_reply":"2025-10-23T09:29:42.722720Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSTARTING TRAINING\n============================================================\nThis will take approximately 15‚Äì25 minutes on a T4 GPU\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1565' max='1565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1565/1565 05:13, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.208500</td>\n      <td>0.153454</td>\n      <td>0.922598</td>\n      <td>0.936766</td>\n      <td>0.929628</td>\n      <td>0.962853</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.104700</td>\n      <td>0.105964</td>\n      <td>0.951526</td>\n      <td>0.957543</td>\n      <td>0.954525</td>\n      <td>0.975006</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.061900</td>\n      <td>0.089324</td>\n      <td>0.957105</td>\n      <td>0.967480</td>\n      <td>0.962264</td>\n      <td>0.979821</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.039500</td>\n      <td>0.095077</td>\n      <td>0.968468</td>\n      <td>0.971093</td>\n      <td>0.969779</td>\n      <td>0.981197</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.022100</td>\n      <td>0.093371</td>\n      <td>0.973850</td>\n      <td>0.975610</td>\n      <td>0.974729</td>\n      <td>0.983031</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nTRAINING COMPLETED!\n============================================================\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# ============================================\n# 14. FINAL EVALUATION\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"FINAL EVALUATION ON VALIDATION SET\")\nprint(\"=\"*60)\neval_results = trainer.evaluate()\nprint(\"\\nValidation Results:\")\nfor key, value in eval_results.items():\n    print(f\"  {key}: {value:.4f}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"EVALUATION ON TEST SET\")\nprint(\"=\"*60)\ntest_results = trainer.evaluate(tokenized_datasets[\"test\"])\nprint(\"\\nTest Results:\")\nfor key, value in test_results.items():\n    print(f\"  {key}: {value:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:29:42.724289Z","iopub.execute_input":"2025-10-23T09:29:42.724578Z","iopub.status.idle":"2025-10-23T09:29:46.847861Z","shell.execute_reply.started":"2025-10-23T09:29:42.724552Z","shell.execute_reply":"2025-10-23T09:29:46.847213Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nFINAL EVALUATION ON VALIDATION SET\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='64' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nValidation Results:\n  eval_loss: 0.0934\n  eval_precision: 0.9739\n  eval_recall: 0.9756\n  eval_f1: 0.9747\n  eval_accuracy: 0.9830\n  eval_runtime: 2.0639\n  eval_samples_per_second: 484.5280\n  eval_steps_per_second: 15.5050\n  epoch: 5.0000\n\n============================================================\nEVALUATION ON TEST SET\n============================================================\n\nTest Results:\n  eval_loss: 0.0935\n  eval_precision: 0.9707\n  eval_recall: 0.9725\n  eval_f1: 0.9716\n  eval_accuracy: 0.9820\n  eval_runtime: 2.0461\n  eval_samples_per_second: 488.7290\n  eval_steps_per_second: 15.6390\n  epoch: 5.0000\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# ============================================\n# 15. SAVE MODEL\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SAVING FINAL MODEL\")\nprint(\"=\"*60)\ntrainer.save_model(\"./banglabert-ner-final\")\ntokenizer.save_pretrained(\"./banglabert-ner-final\")\nprint(\"Model saved to: ./banglabert-ner-final\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:29:46.848565Z","iopub.execute_input":"2025-10-23T09:29:46.848817Z","iopub.status.idle":"2025-10-23T09:29:48.120428Z","shell.execute_reply.started":"2025-10-23T09:29:46.848788Z","shell.execute_reply":"2025-10-23T09:29:48.119596Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSAVING FINAL MODEL\n============================================================\nModel saved to: ./banglabert-ner-final\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# ============================================\n# 16. TEST INFERENCE\n# ============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TESTING INFERENCE\")\nprint(\"=\"*60)\n\ntest_sentence = dataset[\"test\"][0]\ntest_tokens = test_sentence[\"tokens\"]\nprint(f\"\\nTest sentence: {' '.join(test_tokens)}\")\n\ninputs = tokenizer(\n    test_tokens,\n    is_split_into_words=True,\n    return_tensors=\"pt\",\n    truncation=True,\n    padding=True\n).to(device)\n\nwith torch.no_grad():\n    outputs = model(**inputs)\n    predictions = torch.argmax(outputs.logits, dim=2)\n\npredicted_labels = [label_list[p.item()] for p in predictions[0]]\nword_ids = inputs.word_ids()\n\nfinal_predictions = []\nprevious_word_idx = None\nfor word_idx, pred_label in zip(word_ids, predicted_labels):\n    if word_idx is not None and word_idx != previous_word_idx:\n        final_predictions.append(pred_label)\n        previous_word_idx = word_idx\n\nprint(\"\\nPredicted NER tags:\")\nfor token, pred_tag in zip(test_tokens, final_predictions):\n    print(f\"  {token:20s} -> {pred_tag}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ALL DONE! üéâ\")\nprint(\"=\"*60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T09:29:48.121370Z","iopub.execute_input":"2025-10-23T09:29:48.121818Z","iopub.status.idle":"2025-10-23T09:29:48.143481Z","shell.execute_reply.started":"2025-10-23T09:29:48.121786Z","shell.execute_reply":"2025-10-23T09:29:48.142810Z"}},"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nTESTING INFERENCE\n============================================================\n\nTest sentence: ‡¶â‡¶∞‡ßÅ‡¶ó‡ßÅ‡¶Ø‡¶º‡ßá ‡¶ú‡¶æ‡¶§‡ßÄ‡¶Ø‡¶º ‡¶´‡ßÅ‡¶ü‡¶¨‡¶≤ ‡¶¶‡¶≤\n\nPredicted NER tags:\n  ‡¶â‡¶∞‡ßÅ‡¶ó‡ßÅ‡¶Ø‡¶º‡ßá             -> B-ORG\n  ‡¶ú‡¶æ‡¶§‡ßÄ‡¶Ø‡¶º               -> I-ORG\n  ‡¶´‡ßÅ‡¶ü‡¶¨‡¶≤                -> I-ORG\n  ‡¶¶‡¶≤                   -> I-ORG\n\n============================================================\nALL DONE! üéâ\n============================================================\n","output_type":"stream"}],"execution_count":32}]}